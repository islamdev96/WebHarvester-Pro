"""Simple extractor to show results quickly."""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def simple_extract():
    """Extract data simply without complex validation."""
    url = "http://www.expoegypt.gov.eg/exporters"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'lxml')
        
        # Find company containers
        co_nodes = soup.select('.co_node')
        print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(co_nodes)} Ø´Ø±ÙƒØ©")
        
        companies = []
        
        for i, node in enumerate(co_nodes):
            try:
                # Extract company name
                co_title = node.select_one('.co_title')
                company_name = co_title.get_text().strip() if co_title else f"Ø´Ø±ÙƒØ© {i+1}"
                
                # Extract contact info
                contact_info = {}
                
                # Phone
                phone_elem = node.select_one('.co_phone')
                if phone_elem:
                    phone = phone_elem.get_text().strip()
                    if phone:
                        contact_info['phone'] = phone
                
                # Email and website
                co_net = node.select_one('.co_net')
                if co_net:
                    links = co_net.find_all('a')
                    for link in links:
                        href = link.get('href', '')
                        text = link.get_text().strip()
                        if 'mailto:' in href:
                            contact_info['email'] = href.replace('mailto:', '')
                        elif 'www.' in href or 'http' in href:
                            contact_info['website'] = href
                
                # Address
                co_address = node.select_one('.co_address')
                if co_address:
                    address = co_address.get_text().strip()
                    if address:
                        contact_info['address'] = address
                
                # Business sector
                business_info = {}
                ind_sector = node.select_one('.ind_sector')
                if ind_sector:
                    sector_text = ind_sector.get_text().strip()
                    if 'Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„ØµÙ†Ø§Ø¹Ù‰:' in sector_text:
                        sector = sector_text.replace('Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„ØµÙ†Ø§Ø¹Ù‰:', '').strip()
                        if sector:
                            business_info['sector'] = sector
                
                company_data = {
                    'id': f"company_{i+1}",
                    'company_name_arabic': company_name,
                    'contact_info': contact_info,
                    'business_info': business_info,
                    'extracted_at': datetime.now().isoformat()
                }
                
                companies.append(company_data)
                
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø±ÙƒØ© {i+1}: {e}")
                continue
        
        # Create JSON output
        result = {
            'metadata': {
                'extraction_date': datetime.now().isoformat(),
                'source_url': url,
                'total_companies': len(companies)
            },
            'companies': companies
        }
        
        # Save to file
        output_file = "output/simple_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {output_file}")
        
        # Show sample results
        print(f"\nğŸ“Š ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(companies)} Ø´Ø±ÙƒØ© Ø¨Ù†Ø¬Ø§Ø­!")
        print("\nğŸ¢ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø´Ø±ÙƒØ§Øª:")
        
        for i, company in enumerate(companies[:5]):
            name = company.get('company_name_arabic', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            phone = company.get('contact_info', {}).get('phone', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')
            email = company.get('contact_info', {}).get('email', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')
            sector = company.get('business_info', {}).get('sector', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            
            print(f"\n{i+1}. {name}")
            print(f"   ğŸ“ Ø§Ù„Ù‡Ø§ØªÙ: {phone}")
            print(f"   ğŸ“§ Ø§Ù„Ø¥ÙŠÙ…ÙŠÙ„: {email}")
            print(f"   ğŸ­ Ø§Ù„Ù‚Ø·Ø§Ø¹: {sector}")
        
        # Statistics
        companies_with_phone = sum(1 for c in companies if c.get('contact_info', {}).get('phone'))
        companies_with_email = sum(1 for c in companies if c.get('contact_info', {}).get('email'))
        companies_with_website = sum(1 for c in companies if c.get('contact_info', {}).get('website'))
        
        print(f"\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ø±ÙƒØ§Øª: {len(companies)}")
        print(f"   Ø´Ø±ÙƒØ§Øª Ù„Ù‡Ø§ Ù‡Ø§ØªÙ: {companies_with_phone}")
        print(f"   Ø´Ø±ÙƒØ§Øª Ù„Ù‡Ø§ Ø¥ÙŠÙ…ÙŠÙ„: {companies_with_email}")
        print(f"   Ø´Ø±ÙƒØ§Øª Ù„Ù‡Ø§ Ù…ÙˆÙ‚Ø¹: {companies_with_website}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {e}")
        return False

if __name__ == "__main__":
    simple_extract()